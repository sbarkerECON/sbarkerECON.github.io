<!DOCTYPE html>
<html lang="en">
<head>
<title>This is how you keep your dignity and not sell your soul</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="https://unixsheikh.com/feed.rss">
<link rel="shortcut icon" href="../favicon.ico" type="image/x-icon">
<link rel="stylesheet" type="text/css" href="../includes/css/stylesheet.css">
</head>
<body>
<header>
<nav>[ <a class="nav-btn" href="../">Home</a> • <a class="nav-btn" href="../about.html">About</a> • <a class="nav-btn" href="../faq.html">FAQ</a> • <a class="nav-btn" href="../hire-me.html">Hire me</a> • <a class="nav-btn" href="../contact.html">Contact</a> • <a class="nav-btn rss" href="../feed.rss">RSS</a> • <a class="nav-btn" href="../tutorials.html">Tutorials only</a> • <a class="nav-btn" href="../articles.html">Articles only</a> ]</nav>
</header>
<article>

<h1>This is how you keep your dignity and not sell your soul</h1>
<p class="post-data">Published on <span id="pubdate">2021-02-11</span>.</p>
<p class="info info-yellow abstract">In 2020 Laurent Bercot, the developer of the <a href="https://www.skarnet.org/software/s6-linux-init/">s6 init tools</a>, was contacted by a recruiter at Google. He wrote an answer which he made public. That answer deserves to be spread far and wide. I present the answer here as a direct copy from the original.</p>

<p>Source: <a href="https://skarnet.org/text/google.html">https://skarnet.org/text/google.html</a></p>

<p>
 Hi XXXXX,
</p>

<p>
 Thanks for reaching out. I am safe and healthy, and I hope the current
situation finds you safe as well. The timing is not insensitive at all,
I am lucky to be working in an industry that is not significantly
impacted by the sanitary crisis, because in most cases it is possible
for us tech people to work from home, and we have teleconference
software, Google Meet being one of the popular ones. :)
</p>

<p>
 You are asking me if I would be interested in chatting about options
for joining Google again, either in your growing Warsaw site or in
other Google locations.
</p>

<p>
 Since I left Google in 2014, I have undergone quite a bit of growth,
certainly in technical skills, but also in the way that I see and
understand the world, and how I can strive to make it better, and how
technology can make it better, and how powerful tech companies such as
Google can have an impact and use their power for good.
</p>

<p>
 As a result, I would certainly be interested in helping Google make
the world better. But I am not sure that what I have in mind is in line
with what Google has in mind. If I were to work for Google again, in
any capacity, I would first need the assurance that I am working in the
right direction, and that my work will actually bring positive change.
And so far, the direction that Google has taken in recent years does
not give me that assurance. Let me guide you through a few examples.
</p>

<ul>
 <li> I am a big proponent of diversity and inclusion in the workspace.
There was a time where Google was a major voice for progress in this
domain, and my SRE team in Dublin in 2013-2014 was pretty diverse and
inclusive (at least, if you consider that 0 women out of 9 people is
diverse enough). However, this claim for support for inclusion seems
to be changing: <br>
<a href="https://www.nbcnews.com/news/us-news/current-ex-employees-allege-google-drastically-rolled-back-diversity-inclusion-n1206181">
https://www.nbcnews.com/news/us-news/current-ex-employees-allege-google-drastically-rolled-back-diversity-inclusion-n1206181</a><br>
Why has Google rolled back the Sojourn project and cut back other
diversity initiatives? I've heard that it was due to the programs not
scaling, but why does scalability matter more than maintaining programs
that work? Isn't doing good at a small scale better than doing nothing
at a large scale? </li> <p></p>

 <li> If you know anything about me, you know that I am extremely
sensitive to user privacy issues. When I joined the Web SRE team in
2013, I was pleased to see the lengths that Google would go to in
order to strip personally identifiable information from the access logs
of the Google servers. But these last few years, the efforts have seemed
to diminish. For instance, this is what happened a few days ago: <br>
<a href="https://forbes.com/sites/barrycollins/2020/05/15/google-home-hub-shows-random--nest-cam-footage-on-familys-device">
https://forbes.com/sites/barrycollins/2020/05/15/google-home-hub-shows-random--nest-cam-footage-on-familys-device/</a><br>
Back in 2013, with the architecture that Google was using, leaking some
user's data to another user was simply inconceivable. I shiver to
think of the changes, not only at the tech level, but also at the policy
level, that have had to occur in order for such an accident to be
possible. </li><p></p>

 <li> In the same vein, in 2016, Google's commitment to user privacy with
respect to online advertising was silently dropped: <br>
<a href="https://www.propublica.org/article/google-has-quietly-dropped-ban-on-personally-identifiable-web-tracking">
https://www.propublica.org/article/google-has-quietly-dropped-ban-on-personally-identifiable-web-tracking</a><br>
So, the very policy that was the pride and joy of every privacy-conscious
Google worker, the thing that made Google different from Facebook and
other mega tech corporations, not only was dropped, but was dropped
<em>silently</em>. Such a decision seems too important to be kept quiet; it is
a significant change. Could this be that Google did something they
<em>knew</em> was wrong? If both the commitment to user privacy and the
commitment to transparency were abandoned, what makes Google different
from Facebook today? </li><p></p>

 <li> Another recent example that shows Google is not the privacy-conscious
company it once was: <br>
<a href="https://www.bloomberg.com/news/articles/2020-05-13/google-faces-eu-privacy-complaint-for-tracking-users">
https://www.bloomberg.com/news/articles/2020-05-13/google-faces-eu-privacy-complaint-for-tracking-users</a><br>
Privacy is not only important to me, it is also important to the
EU jurisdictions. What assurance could I get that my work would not be
used for illegal purposes? </li><p></p>

 <li> A lot has been written about YouTube in these recent years, and in
particular its recommendation algorithm. YouTube has the manpower to
tweak its recommendation algorithm, as it has shown recently by
deprioritizing independent content in favor of "authoritative sources",
i.e. corporate sources. Still, back when it was crucial and could
impact the world for the better in a very real, very significant way,
YouTube refused to tweak the levers. For instance, this is what
happened: <br>
<a href="https://www.nytimes.com/2019/08/11/world/americas/youtube-brazil.html">
https://www.nytimes.com/2019/08/11/world/americas/youtube-brazil.html</a><br>
At the time, YouTube (and more generally, Google) spokespeople said
that they did not want to be censors, they did not want to have a hand
in what content was favored and what content was not. A principled
stance, which can be argued against but which can also be argued for,
and principles are generally a good thing. However, these principles
did not seem to hold any water, because YouTube is now happily tweaking
its algorithm, not to silence anti-science voices, but to silence
dissident voices in an increasingly authoritarian world. What happened,
and why is it looking so bad? </li><p></p>

 <li> Climate change is real. It is important that everyone understands
this. Yet, last year, Google sponsored a conference hosting climate
change denialists: <br>
<a href="https://www.theverge.com/2019/1/23/18194432/facebook-google-microsoft-libertycon-climate-change">
https://www.theverge.com/2019/1/23/18194432/facebook-google-microsoft-libertycon-climate-change</a><br>
I can certainly think of other, better ways of using Google money to
make a positive change in the world. If I can, why can't the decision
makers at the top levels of Google? </li><p></p>

 <li> An important way for rich people, and rich companies, to be a part
of the collective effort to make the world a more just, more equitable
place, is to pay their fair share of taxes. Unfortunately, it seems
that Google does not do that, either: <br>
<a href="https://www.theguardian.com/technology/2013/may/16/google-told-by-mp-you-do-do-evil">
https://www.theguardian.com/technology/2013/may/16/google-told-by-mp-you-do-do-evil</a><br>
As per the article, it was <em>already</em> not doing that when I was hired in
2013. At the time there was a widely publicized claim among Googlers
that once you were hired, you could have access to <em>any</em> information
about the workings of Google. I did inquire a bit about the financing
models and the revenue flow, and I find it curious that I never heard
anything about tax avoidance. It may be that the clamored openness was
not as thorough as everyone pretended to believe it was. </li>
</ul>

 <p>
 All those items are pretty damning, if we are looking at how Google
impacts the world at large. But you could still have a chance at
appealing to the nerd in me, the person who loves technology and who
wants to make cool things. Because at least at Google we make
good tech, right? Well, about that...<br>
<a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/">
https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/</a><br>
How is it possible to be so short-sighted with regards to testing
software as to fail to include black people in the Photos AI training
set, with such an embarrassing result? How can I pretend to be one of
the top engineers in the world if I'm working at a company that makes
this kind of rookie mistake?
</p>

<p>
 Oh, and wouldn't an initiative such as the Sojourn project, the one
that was abandoned, have precisely prevented that fiasco, by making
sure that an appropriately diverse sample of subjects would be
submitted to the training set?
</p>

<p>
 And it is far from the only example. There are other fundamental,
elementary mistakes, some of which are much more related to my skill set and
that I am much more qualified to talk about in detail, but since I am
a systems engineer, these are not the things that get much publicity
and are widely available on the Web. I will still give the following
example:
</p>

<p>
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p2137r0.html#platforms">
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p2137r0.html#platforms</a><br>
This proposal, for the next standard of C++, which is a general-purpose
programming language, lists hardware architectures, OS platforms,
and environments that should be prioritized. <br>
From a technical point of view, this is absolute nonsense. It is not
the place of a programming language to prioritize hardware architectures
or OS platforms. It is the job of a compiler for this language to
implement the specification for various platforms and the implementation
may be more or less optimized depending on the backend, but the language
itself should be entirely agnostic. <br>
And even if you accept the premise that it makes sense to define a list
of priorities, let's take a look: none of the various BSD operating
systems have made the list, despite having significant, vibrant
communities and a long history of working, but Fuchsia, Google's own,
not-ready-yet operating system, has. Hmmm. Also, there is a curious
insistence on prioritizing little-endian hardware, which would be
detrimental to a certain number of embedded systems and other platforms,
but it so happens that Google uses none of them.
</p>

<p>
 And it just so happens that out of the 17 authors of that document,
8 of them are working at Google.
</p>

<p>
 So even in my narrow, restricted field, what I witness of Google's
influence in the world is an attempt to infiltrate and subvert
communities and standards committees, in order to influence them
towards goals that directly benefit Google, and without any care or
consideration for the rest of the community, or for the actual technical
quality of the results.
</p>

<p>
 So, after this long development, let me sum this up by saying that I
would be extremely glad to be offered a position at Google, if it was
in the executive committee, if I had direct control over a product that
I could actually make <em>good</em>, as in, good for the users and for the
world, not only for Google's shareholders. Or if it was in the ethics
committee, where I could actually influence the direction Google is
going, and had the power to make it stop ruining the world and
making life worse for everyone, in technical matters or otherwise. But
somehow I don't think it's what you were thinking about when you
reached out to me. <br>
 And if it's about taking up another tech position, where I need to
pour my heart and soul into maintaining products that infringe on user
privacy, undermine civil liberties, and threaten democracy and
ultimately life on Earth, then it is probably safe to say that I would
rather drag my scrotum across a mile of sandpaper than accept such a
position.
</p>

<p>
 Coarse-grained. (The sandpaper.)
</p>

<p>
 You are directly responsible for none of the evils I listed above,
so I beg you not to take this answer personally. However, I would
certainly encourage you to read this e-mail again, and to show it
to your coworkers who are also hunting for new talent, so that every
single one of you can take a good look in the mirror, a deep breath,
and a moment for introspection and reflection on your life choices.
</p>

<p>
 I wish you the best,
</p>

<p>
 Laurent
</p>

</article>
<footer><i>If you have any comments or corrections please feel free to email them to me. Also, if you found this content useful consider supporting me on <a href="https://patreon.com/unixsheikh">Patreon</a></i> ;)</footer>
</body>
</html>
